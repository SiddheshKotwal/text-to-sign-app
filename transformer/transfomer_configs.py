config_1 = {
    "encoder": {
        "type": "transformer",
        "num_layers": 1,
        "num_heads": 4,
        "hidden_size": 256,
        "ff_size": 512,
        "dropout": 0.2,
        "freeze": False,
        "layer_norm": "pre",
        "activation": "relu",
    },
    "decoder": {
        "type": "transformer",
        "num_layers": 1,
        "num_heads": 4,
        "hidden_size": 256,
        "ff_size": 512,
        "dropout": 0.2,
        "freeze": False,
        "layer_norm": "pre",
        "activation": "relu",
    },
}
config_2 = {
    "encoder": {
        "type": "transformer",
        "num_layers": 1,
        "num_heads": 4,
        "hidden_size": 512,
        "ff_size": 1024,
        "dropout": 0.2,
        "freeze": False,
        "layer_norm": "pre",
        "activation": "relu",
    },
    "decoder": {
        "type": "transformer",
        "num_layers": 1,
        "num_heads": 4,
        "hidden_size": 512,
        "ff_size": 1024,
        "dropout": 0.2,
        "freeze": False,
        "layer_norm": "pre",
        "activation": "relu",
    },
}
config_3 = {
    "encoder": {
        "type": "transformer",
        "num_layers": 2,
        "num_heads": 4,
        "hidden_size": 256,
        "ff_size": 512,
        "dropout": 0.2,
        "freeze": False,
        "layer_norm": "pre",
        "activation": "relu",
    },
    "decoder": {
        "type": "transformer",
        "num_layers": 2,
        "num_heads": 4,
        "hidden_size": 256,
        "ff_size": 512,
        "dropout": 0.2,
        "freeze": False,
        "layer_norm": "pre",
        "activation": "relu",
    },
}
config_4 = {
    "encoder": {
        "type": "transformer",
        "num_layers": 2,
        "num_heads": 4,
        "hidden_size": 512,
        "ff_size": 1024,
        "dropout": 0.2,
        "freeze": False,
        "layer_norm": "pre",
        "activation": "relu",
    },
    "decoder": {
        "type": "transformer",
        "num_layers": 2,
        "num_heads": 4,
        "hidden_size": 512,
        "ff_size": 1024,
        "dropout": 0.2,
        "freeze": False,
        "layer_norm": "pre",
        "activation": "relu",
    },
}
config_3 = {
    "encoder": {
        "type": "transformer",
        "num_layers": 2,
        "num_heads": 4,
        "hidden_size": 256,
        "ff_size": 512,
        "dropout": 0.2,
        "freeze": False,
        "layer_norm": "pre",
        "activation": "relu",
    },
    "decoder": {
        "type": "transformer",
        "num_layers": 2,
        "num_heads": 4,
        "hidden_size": 256,
        "ff_size": 512,
        "dropout": 0.2,
        "freeze": False,
        "layer_norm": "pre",
        "activation": "relu",
    },
}
config_5 = {
    "encoder": {
        "type": "transformer",
        "num_layers": 4,
        "num_heads": 4,
        "hidden_size": 512,
        "ff_size": 1024,
        "dropout": 0.2,
        "freeze": False,
        "layer_norm": "pre",
        "activation": "relu",
    },
    "decoder": {
        "type": "transformer",
        "num_layers": 4,
        "num_heads": 4,
        "hidden_size": 512,
        "ff_size": 1024,
        "dropout": 0.2,
        "freeze": False,
        "layer_norm": "pre",
        "activation": "relu",
    },
}

transformer_modes = {1: config_1}
